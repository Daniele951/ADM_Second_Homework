{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f35c73d",
   "metadata": {},
   "source": [
    "# ADM Homework 2 (Group # 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0171c2d",
   "metadata": {},
   "source": [
    "## Team Members "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741b0f2",
   "metadata": {},
   "source": [
    "1. Syed Muhammad Hassan Raza (hasanrezacs@gmail.com)\n",
    "2. Daniele Pristerà (pristera.1657095@studenti.uniroma1.it)\n",
    "3. Riccardo Agabiti (riccardoagabiti98@gmail.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7b7356",
   "metadata": {},
   "source": [
    "### Installing/Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70d93575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pandas\n",
    "# !pip install numpy\n",
    "# !pip install matplotlib.pyplot\n",
    "# !pip install math\n",
    "# !pip install pandasql\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pandasql import sqldf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5765dca",
   "metadata": {},
   "source": [
    "### Loading Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0117fc42",
   "metadata": {},
   "source": [
    "As the given dataset has timestamp values in unix, we need a function to convert unix timestamps to datetime values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5888f25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below function converts unix timestamps into datetime\n",
    "\n",
    "def dateparse(time_in_secs):\n",
    "    return pd.to_datetime(time_in_secs, unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7fc922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading steam_reviews.csv file into a pandas dataframe\n",
    "\n",
    "df = pd.read_csv('.\\steam_reviews.csv', header='infer', nrows=1000000, parse_dates=['timestamp_created',\n",
    "'timestamp_updated', 'author.last_played'], date_parser=dateparse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdfe561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 rows of the dataset\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302645e",
   "metadata": {},
   "source": [
    "# Research Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9395b7",
   "metadata": {},
   "source": [
    "## [RQ1] Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a48f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about dataset dimension\n",
    "\n",
    "nrows, ncolumns = df.shape\n",
    "print(\"Dataset has {} rows and {} columns\".format(nrows, ncolumns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c809fc5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information about dataset columns\n",
    "\n",
    "print(\"Dataset has the following columns:\")\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78e3102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .info() function shows brief information about the dataset\n",
    "\n",
    "print(\"Brief information about the dataset:\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d4a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The first review was created on:\")\n",
    "df.timestamp_created.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c162c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"While the latest review was updated on:\")\n",
    "df.timestamp_updated.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d93ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lang_count = df.language.nunique()\n",
    "\n",
    "print(\"Reviews are written in the following {} languages:\".format(lang_count))\n",
    "df.language.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581fef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count of reviews per each language is:\")\n",
    "df.groupby('language').review_id.count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"No. of reviews wrt. day of the week:\")\n",
    "df.groupby(df.timestamp_created.dt.weekday).review_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e803ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics wrt timestamp_created and language of the review\n",
    "\n",
    "df.groupby([df.timestamp_created.dt.hour, df.language]).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7154092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of the review count wrt language in which the review is written\n",
    "\n",
    "df['language'].value_counts().plot.bar(\\\n",
    "figsize = (18, 9),\\\n",
    "title='Top Languages', \\\n",
    "xlabel='Language',\\\n",
    "ylabel='Number of Reviews')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a404a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Piechart for the distribution of languages\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.pie(df['language'].value_counts(),\n",
    "labels = df.language.unique(),\n",
    "explode = [0.1 for value in range(0, df.language.nunique())],\n",
    "shadow = True, autopct = '%.1f%%')\n",
    "plt.title('Languages', fontsize = 20)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b062f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hour_reviews = df.groupby(df.timestamp_created.dt.hour)\n",
    "\n",
    "plt.figure()\n",
    "hour_reviews.votes_funny.sum().plot()\n",
    "plt.xlabel(\"Hour of Day\")\n",
    "plt.ylabel(\"Total Funny Votes\")\n",
    "plt.xticks(range(0,24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5440949d",
   "metadata": {},
   "source": [
    "There's a **sqldf** function inside pandasql library, which allows us to interact with a dataframe with SQL queries. It also returns a dataframe object. Therefore we use sqldf function for most of the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01950dcf",
   "metadata": {},
   "source": [
    "## [RQ2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c55f70",
   "metadata": {},
   "source": [
    "### number of reviews for each application in descending order?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bcd503",
   "metadata": {},
   "source": [
    "We use app_id column to group the number of reviews because it's a unique identity for each application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106f00eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['app_id'].value_counts().plot.bar(title='# of reviews for each application',\\\n",
    "                                     xlabel='app_id',\\\n",
    "                                     ylabel='count',\n",
    "                                     figsize= (18, 9))\n",
    "\n",
    "# plot represent the no. of reviews for each application in descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba7c005",
   "metadata": {},
   "source": [
    "### What applications have the best Weighted Vote Score?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e04e5bf",
   "metadata": {},
   "source": [
    "For each application, we found the max of its weighted_vote_score and sorted the result in descending order to know what applications have the best weighted score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191d05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_weighted_score_apps = sqldf(\"select distinct(app_id), app_name, max(weighted_vote_score) AS Weight_Score\\\n",
    "                                  from df group by app_id order by Weight_Score desc\")\n",
    "\n",
    "best_weighted_score_apps\n",
    "\n",
    "# table representing apps with the best Weighted Score (top to bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec08039",
   "metadata": {},
   "source": [
    "### Which applications have the most and the least recommendations?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b759e19",
   "metadata": {},
   "source": [
    "For each application, we found the review count where a review was given a positive recommendation and sorted the result in descending order to know what applications have the most recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31be0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_recommended_apps = sqldf(\"select distinct(app_id), app_name, count(recommended) AS Count\\\n",
    "                               from df where recommended=True group by app_id order by Count desc\")\n",
    "\n",
    "most_recommended_apps\n",
    "\n",
    "# table representing most recommended apps (top to bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf06a977",
   "metadata": {},
   "source": [
    "For each application, we found the review count where a review was given a positive recommendation and sorted the result in ascending order to know what applications have the least recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4b8da6c",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "IO Error: No files found that match the pattern \"df.parquet\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-244e818f38ac>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#least_recommended_apps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m least_recommended_apps = db.query(\"select distinct(app_id), app_name, count(recommended) AS Count\\\n\u001b[0m\u001b[0;32m      6\u001b[0m                                from 'df.parquet' where recommended=True group by app_id order by Count asc\").to_df()\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: IO Error: No files found that match the pattern \"df.parquet\""
     ]
    }
   ],
   "source": [
    "#least_recommended_apps = sqldf(\"select distinct(app_id), app_name, count(recommended) AS Count\\\n",
    "                              # from df where recommended=True group by app_id order by Count asc\")\n",
    "\n",
    "#least_recommended_apps\n",
    "least_recommended_apps = db.query(\"select distinct(app_id), app_name, count(recommended) AS Count\\\n",
    "                               from 'df.parquet' where recommended=True group by app_id order by Count asc\").to_df()\n",
    "\n",
    "least_recommended_apps\n",
    "\n",
    "\n",
    "\n",
    "# table representing least recommended apps (top to bottom)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5d8e35",
   "metadata": {},
   "source": [
    "### How many of these applications were purchased, and how many were given for free?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc99c2f",
   "metadata": {},
   "source": [
    "For each application, we found how many times it was purchased on Steam by the users using **steam_purchase = True** condition. Then we summed up the purchase count for each application to get the total number of purchased applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b859b899",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_purchased = sqldf(\"select distinct(app_id), app_name, count(steam_purchase) AS Purchased_Count\\\n",
    "                         from df where steam_purchase=True group by app_id order by Purchased_Count desc\")\n",
    "\n",
    "count_purchased_ = sqldf(\"select sum(Purchased_Count) AS Count_Purchased from count_purchased\")\n",
    "count_purchased_\n",
    "\n",
    "# Total no. of applications purchased on Steam (see Count_Purchased column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e108d66",
   "metadata": {},
   "source": [
    "For each application, we found how many times it was got as free by the users using **received_for_free = True** condition. Then we summed up the free count for each application to get the total number of applications received for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19a30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_free = sqldf(\"select distinct(app_id), app_name, count(received_for_free) AS Free_Count\\\n",
    "                    from df where received_for_free=True group by app_id order by Free_Count desc\")\n",
    "\n",
    "count_free_ = sqldf(\"select sum(Free_Count) AS Count_Free from count_free\")\n",
    "count_free_\n",
    "\n",
    "# Total no. of total applications received for free (see Count_Free column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36968fbb",
   "metadata": {},
   "source": [
    "## [RQ3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878267e7",
   "metadata": {},
   "source": [
    "### What is the most common time that authors review an application?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3f6cec",
   "metadata": {},
   "source": [
    "Since we were supposed to provide the answer in H:M format, we converted datetime values in the H:M format first. Then we counted how many reviews were written for each H:M time. We then selected the time in which the maximum number of reviews were written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c58dc31",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common_time = sqldf(\"select strftime('%H:%M', timestamp_created) AS Time, count(review_id) AS Review_Count from df\\\n",
    "                          group by [Time]\\\n",
    "                          order by Review_Count desc\")\n",
    "\n",
    "most_common_time_ = sqldf(\"select Time, max(Review_Count) AS 'Count of reviews' from most_common_time\")\n",
    "most_common_time_\n",
    "\n",
    "# Most common time when authors review an application (see Time column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a8e8d0",
   "metadata": {},
   "source": [
    "### Create a function that receives as a parameter a list of time intervals and returns the plot the number of reviews for each of the intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41c45660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that takes a list of time intervals as a parameter and returns the plot of the no. of reviews for each of the interval\n",
    "\n",
    "def time_interval_plot(list_):   \n",
    "    x = [] # list for x-axis values (time intervals) which will be populated upon the function call\n",
    "    y = [] # list for y-axis values (count of reviews in the given interval) which will be populated upon the function call\n",
    "    \n",
    "    for start_, end_ in list_:\n",
    "        # query that gives the count of reviews for each of the provided time intervals\n",
    "        query = \"select count(review_id) AS Count from df\\\n",
    "                 where strftime('%H:%M:%S', timestamp_created) between '{}' and '{}'\".format(start_, end_)\n",
    "        res = sqldf(query)\n",
    "        y.append(res.iloc[0]['Count']) # populate the list y\n",
    "        \n",
    "    for start_, end_ in list_:\n",
    "        x.append(\"{} - {}\".format(start_, end_)) # populate the list x\n",
    "    \n",
    "    # settings for plot\n",
    "    fig = plt.figure(figsize = (18, 9)) # figure size\n",
    "    plt.bar(x, y) # bar plot for x, y values\n",
    "    plt.xlabel(\"Intervals\")\n",
    "    plt.xticks(rotation='vertical')\n",
    "    plt.ylabel(\"Review Count\")\n",
    "    plt.title(\"# of reviews wrt time intervals\")\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b56db0d",
   "metadata": {},
   "source": [
    "### Use the function that you created in the previous literal to plot the number of reviews between the following time intervals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a615c9d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 76.3 MiB for an array with shape (10000000,) and data type object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-1642d0d4ce03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m              [\"20:00:00\", \"23:59:59\"], [\"00:00:00\", \"02:59:59\"], [\"03:00:00\", \"05:59:59\"]]\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_interval_plot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mintervals\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Function call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-852fb146739c>\u001b[0m in \u001b[0;36mtime_interval_plot\u001b[1;34m(list_)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mquery\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\"\u001b[0m\u001b[0mselect\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreview_id\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mCount\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                  \u001b[0mwhere\u001b[0m \u001b[0mstrftime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'%H:%M:%S'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimestamp_created\u001b[0m\u001b[1;33m)\u001b[0m \u001b[0mbetween\u001b[0m \u001b[1;34m'{}'\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'{}'\u001b[0m\u001b[0;31m\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msqldf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mres\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Count'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# populate the list y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandasql\\sqldf.py\u001b[0m in \u001b[0;36msqldf\u001b[1;34m(query, env, db_uri)\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;33m>>\u001b[0m\u001b[1;33m>\u001b[0m \u001b[0msqldf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"select avg(x) from df;\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m     \"\"\"\n\u001b[1;32m--> 156\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPandaSQL\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdb_uri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandasql\\sqldf.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, query, env)\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloaded_tables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                 \u001b[0mwrite_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandasql\\sqldf.py\u001b[0m in \u001b[0;36mwrite_table\u001b[1;34m(df, tablename, conn)\u001b[0m\n\u001b[0;32m    118\u001b[0m         filterwarnings('ignore',\n\u001b[0;32m    119\u001b[0m                        message='The provided table name \\'%s\\' is not found exactly as such in the database' % tablename)\n\u001b[1;32m--> 120\u001b[1;33m         to_sql(df, name=tablename, con=conn,\n\u001b[0m\u001b[0;32m    121\u001b[0m                index=not any(name is None for name in df.index.names))  # load index into db if all levels are named\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m    599\u001b[0m         )\n\u001b[0;32m    600\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m     pandas_sql.to_sql(\n\u001b[0m\u001b[0;32m    602\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   1409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1410\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1411\u001b[1;33m             \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1412\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSQLAlchemyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1413\u001b[0m             \u001b[1;31m# GH34431\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36minsert\u001b[1;34m(self, chunksize, method)\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Invalid parameter `method`: {method}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m         \u001b[0mkeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36minsert_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    796\u001b[0m                 \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"i8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 798\u001b[1;33m                 \u001b[0md\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvals\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    800\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 76.3 MiB for an array with shape (10000000,) and data type object"
     ]
    }
   ],
   "source": [
    "# Intervals given in the homework\n",
    "\n",
    "intervals = [[\"06:00:00\", \"10:59:59\"], [\"11:00:00\", \"13:59:59\"], [\"14:00:00\", \"16:59:59\"], [\"17:00:00\", \"19:59:59\"],\n",
    "             [\"20:00:00\", \"23:59:59\"], [\"00:00:00\", \"02:59:59\"], [\"03:00:00\", \"05:59:59\"]]\n",
    "\n",
    "x = time_interval_plot(intervals) # Function call\n",
    "x.show()\n",
    "\n",
    "# Plot representing the no. of reviews between the provided time intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0edcd8",
   "metadata": {},
   "source": [
    "## [RQ4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05cae187",
   "metadata": {},
   "source": [
    "### What are the top 3 languages used to review applications?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fca97a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('language').review_id.count().nlargest(3)\n",
    "\n",
    "# top 3 languages used to review apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7ee3a3",
   "metadata": {},
   "source": [
    "### Create a function that receives as parameters both the name of a data set and a list of languages’ names and returns a data frame filtered only with the reviews written in the provided languages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8133353",
   "metadata": {},
   "source": [
    "This function filters the dataframe based on the language column values. If the review language is in one of the **langs** values, it adds that review to the filtered dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0fbf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to filter dataframe with respect to given list of languages\n",
    "\n",
    "def language_filter(dataframe, langs):\n",
    "    return dataframe[dataframe.language.isin(langs)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f3b204",
   "metadata": {},
   "source": [
    "### Use the function created in the previous literal to find what percentage of these reviews (associated with the top 3 languages) were voted as funny?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d0372b",
   "metadata": {},
   "outputs": [],
   "source": [
    "langs = ['english', 'russian', 'schinese'] # from part 1 of RQ4\n",
    "\n",
    "res = language_filter(df, langs) # Function call\n",
    "\n",
    "x = round((len(res[res[\"votes_funny\"] != 0])/len(res))*100, 2)\n",
    "print(\"{}% of these reviews (associated with the top 3 languages) were voted as funny\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e290c90",
   "metadata": {},
   "source": [
    "### Use the function created in the literal “a” to find what percentage of these reviews (associated with the top 3 languages) were voted as helpful?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfeb0985",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = round((len(res[res[\"votes_helpful\"] != 0])/len(res))*100, 2)\n",
    "print(\"{}% of these reviews (associated with the top 3 languages) were voted as helpful\".format(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8a5c7a",
   "metadata": {},
   "source": [
    "## [RQ5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58dda1a",
   "metadata": {},
   "source": [
    "### Plot the top 10 most popular reviewers and the number of reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beef868b",
   "metadata": {},
   "source": [
    "To get the 10 most popular reviewers, we group the result by the unique entity: author.steamid. Then we pick the maximum value of the author.num_reviews column against each author.steamid. Then we sort the result in descending order by count and pick the top 10 rows to know who are the top 10 most popular reviewers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac76461",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select distinct([author.steamid]), max([author.num_reviews]) AS Count from df\\\n",
    "        group by [author.steamid] order by Count desc LIMIT 10\"\n",
    "\n",
    "popular_reviewers = sqldf(query)\n",
    "\n",
    "popular_reviewers.plot(x ='author.steamid', y='Count', kind = 'bar', figsize= (18, 9))\n",
    "\n",
    "# Plot representing the top 10 most popular reviewers and the number of reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222c1e1f",
   "metadata": {},
   "source": [
    "### What applications did the most popular author review?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0a6975",
   "metadata": {},
   "source": [
    "We picked the most popular reviewer's id (first one) from the previous part to filter what games he has reviewed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9539450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"author.steamid\"] == 76561198125392509].app_name.unique() # Copy steam id of the first author and paste here\n",
    "\n",
    "# The most popular author reviewed the following apps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c39be",
   "metadata": {},
   "source": [
    "### How many applications did he purchase, and how many did he get as free? Provide the number (count) and the percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd44290",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_reviewer = df[df[\"author.steamid\"] == 76561198125392509] # all reviews of the most popular reviewer\n",
    "\n",
    "#apps purchased\n",
    "purchased_count = len(top_reviewer[top_reviewer[\"steam_purchase\"] == True]) # count of purchased apps\n",
    "purchased_percentage = round(purchased_count/len(top_reviewer)*100, 2) # percentage of purchased apps\n",
    "\n",
    "#apps for free\n",
    "free_count = len(top_reviewer[top_reviewer[\"received_for_free\"] == True]) # count of apps received for free\n",
    "free_percentage = round(free_count/len(top_reviewer)*100, 2) # percentage of apps received for free\n",
    "\n",
    "print(\"The most popular reviewer purchased {} ({}% of the) application(s) on Steam.\\n\\\n",
    "The most popular reviewer got {} ({}% of the) application(s) for free.\".format(purchased_count, purchased_percentage, \n",
    "                                                                                       free_count, free_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eeed540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#top_reviewer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aacc50e",
   "metadata": {},
   "source": [
    "### How many of the applications he purchased reviewed positively, and how many negatively? How about the applications he received for free?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb188de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "apps_purchased = top_reviewer[top_reviewer[\"steam_purchase\"] == True] # all reviews where apps were purchased\n",
    "apps_free = top_reviewer[top_reviewer[\"received_for_free\"] == True] # all reviews where apps were received as free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84516ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apps_purchased\n",
    "#apps_free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eec3040",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchased_positive_count = len(apps_purchased[apps_purchased[\"recommended\"] == True]) # count of purchased apps where they were reviewed positively\n",
    "purchased_negative_count = len(apps_purchased[apps_purchased[\"recommended\"] == False]) # count of purchased apps where they were reviewed negatively\n",
    "\n",
    "print(\"Out of all the applications he purchased, {} applications reviewed positively.\".format(purchased_positive_count))\n",
    "print(\"Out of all the applications he purchased, {} applications reviewed negatively.\\n\".format(purchased_negative_count))\n",
    "\n",
    "free_positive_count = len(apps_free[apps_free[\"recommended\"] == True]) # count of free apps where they were reviewed positively\n",
    "free_negative_count = len(apps_free[apps_free[\"recommended\"] == False]) # count of free apps where they were reviewed negatively\n",
    "print(\"Out of all the applications he received for free, {} applications reviewed positively.\".format(free_positive_count))\n",
    "print(\"Out of all the applications he received for free, {} applications reviewed negatively.\".format(free_negative_count))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66b604c",
   "metadata": {},
   "source": [
    "## [RQ6]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3606d",
   "metadata": {},
   "source": [
    "### What is the average time (days and minutes) a user lets pass before he updates a review?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1d680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating time difference (in seconds) for each of the review in the dataset\n",
    "query1 = \"select review_id, timestamp_created, timestamp_updated,\\\n",
    "         Cast((JulianDay(timestamp_updated) - JulianDay(timestamp_created))*24*60*60 As Integer) AS DEL from df\\\n",
    "         where DEl <> 0 order by DEL desc\"\n",
    "\n",
    "res1 = sqldf(query1)\n",
    "\n",
    "# Calculating average time difference (in seconds)\n",
    "query2 = \"select cast(AVG(DEL) as integer) AS 'Average_Time' from res1\"\n",
    "res2 = sqldf(query2)\n",
    "\n",
    "# Converting time in seconds to days and minutes\n",
    "query3 = \"SELECT CAST((Average_Time) / (60 * 60 * 24) AS TEXT) || ' day(s) and ' ||\\\n",
    "         CAST(((Average_Time) % (60 * 60 * 24)) / (60) AS TEXT) || ' minute(s)' AS Avg_Time from res2\"\n",
    "\n",
    "time_ = sqldf(query3)\n",
    "time_ # Average time (in days and minutes) a user lets pass before he updates a review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2a44951",
   "metadata": {},
   "source": [
    "### Plot the top 3 authors that usually update their reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20523fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"select distinct([author.steamid]), count(review_id) AS Count from df\\\n",
    "         where timestamp_created <> timestamp_updated group by [author.steamid] order by Count desc LIMIT 3\"\n",
    "\n",
    "sqldf(query).plot(x ='author.steamid', y='Count', kind = 'bar') # plot representing reviews update count of top 3 authors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf918fa",
   "metadata": {},
   "source": [
    "## [RQ7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff787ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The probability of having a review with score bigger than 0.5 can be calculeted dividing the number of favorable cases  \n",
    "# with the total number of reviews.\n",
    "\n",
    "numb_greater_05 = sqldf(\"select count(*) AS Weight_Score\\\n",
    "            from df where weighted_vote_score > 0.5\")\n",
    "\n",
    "total_numb= sqldf(\"select count(*) AS Weight_Score\\\n",
    "            from df\")\n",
    "probability_greater05=numb_greater_05/total_numb\n",
    "probability_greater05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc05387",
   "metadata": {},
   "source": [
    "The conditional probability between having a review labeled as funny given the a score gretar than 0.5 is calculated dividing the intersection between the two sets (the reviews that are simultaneously finny and with score greater than 0.5) and the numbers of review with score greater then 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e40488",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numb_greater05_and_funny= sqldf(\"select count(*) AS Weight_Score\\\n",
    "            from df where (weighted_vote_score > 0.5) and (votes_funny >= 1)\")\n",
    "probability_funny_given_greater05=numb_greater05_and_funny/numb_greater_05\n",
    "probability_funny_given_greater05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a67fca",
   "metadata": {},
   "source": [
    "To verify if the two probabilities (P(score>0.5) and P(isfunny)) are indipendent we should check if they factorized, so if (P(A|B)=P(A)*P(B))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to find the probabilities of a review being funny\n",
    "number_of_funny_reviews=sqldf(\"select count(*) AS Weight_Score\\\n",
    "            from df where (votes_funny >= 1)\")\n",
    "\n",
    "probability_review_funny= number_of_funny_reviews/total_numb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d788b565",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to calculate the total probabilities\n",
    "prob_total=probability_greater05*probability_review_funny\n",
    "prob_total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca62bc1",
   "metadata": {},
   "source": [
    "Since the equation (P(A|B)=P(A)*P(B)) is not verified, the two probabilities are dependent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a8bb2a",
   "metadata": {},
   "source": [
    "## [RQ8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef87e0ef",
   "metadata": {},
   "source": [
    "# Theoretical Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0a3315d",
   "metadata": {},
   "source": [
    "## [TQ1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1b6a02",
   "metadata": {},
   "source": [
    "\n",
    "# Solution of TQ1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92acff3b",
   "metadata": {},
   "source": [
    "![alt text](TQ1_1.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d63988",
   "metadata": {},
   "source": [
    "## [TQ2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee5f30d",
   "metadata": {},
   "source": [
    "![alt text](TQ2_1.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7943f1d6",
   "metadata": {},
   "source": [
    "![alt text](TQ2_3.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d700dd",
   "metadata": {},
   "source": [
    "![alt text](TQ2_4.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f3dc4c",
   "metadata": {},
   "source": [
    "![alt text](TQ2_5.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1c8f6e",
   "metadata": {},
   "source": [
    "![alt text](TQ2_6.jpg \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2871a67a",
   "metadata": {},
   "source": [
    "## [TQ3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa296516",
   "metadata": {},
   "source": [
    "![alt text](TQ3_1.jpg \"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
